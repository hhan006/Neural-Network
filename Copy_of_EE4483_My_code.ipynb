{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of EE4483 My code",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "kZTI6iZVghyH",
        "colab_type": "code",
        "outputId": "52f6cbdd-9053-4f75-e17f-9b6431647872",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys    \n",
        "print(\"Python version: {}\".format(sys.version_info[0]))\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore') # to suppress unnecessary warnings\n",
        "\n",
        "try:\n",
        "    import torch\n",
        "    print(\"PyTorch is already installed, good to go!\") \n",
        "except:\n",
        "    from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "    platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "    accelerator = 'cu80' if os.path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "    !pip install -q \\\n",
        "      http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl \\\n",
        "      torchvision\n",
        "    print(\"Successfully installed PyTorch!\")\n",
        "    import torch"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python version: 3\n",
            "PyTorch is already installed, good to go!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RQdjXetHhHVw",
        "colab_type": "code",
        "outputId": "8845987a-e22a-4f86-86da-1d43e452b9c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import matplotlib.pyplot as plt  # for plots\n",
        "import numpy as np  # for working with numbers and arrays of numbers\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "\n",
        "import random\n",
        "seed = 1\n",
        "random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "print(\"Setup is done!\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setup is done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qTNE23zxhNYG",
        "colab_type": "code",
        "outputId": "5a3bbb2d-735c-469a-dc60-747c30be0af4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "mnist_dir = 'datasets/MNIST' # the directory our data will be downloaded too\n",
        "\n",
        "transformed_dataset = datasets.MNIST(mnist_dir, train=True, download=True,\n",
        "                       transform=transforms.Compose([\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize((0.1307,), (0.3081,)) # normalizing to the [-1,1] range\n",
        "                       ]))\n",
        "\n",
        "for i in range(len(transformed_dataset)):\n",
        "    sample = transformed_dataset[i]\n",
        "\n",
        "    print(i, sample[0].size(), sample[1].size())\n",
        "\n",
        "    if i == 3:\n",
        "        break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 torch.Size([1, 28, 28]) torch.Size([])\n",
            "1 torch.Size([1, 28, 28]) torch.Size([])\n",
            "2 torch.Size([1, 28, 28]) torch.Size([])\n",
            "3 torch.Size([1, 28, 28]) torch.Size([])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RJw2eotyhQ25",
        "colab_type": "code",
        "outputId": "a43078b8-12cc-4097-b5ec-bc6da684f2c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "def load_MNIST(mnist_dir, batch_size, test_batch_size, kwargs):\n",
        "\n",
        "  # Dataloader object is used to organize training data neatly into batches\n",
        "  # it is a part of the PyTorch framework\n",
        "  train_loader = torch.utils.data.DataLoader(\n",
        "        datasets.MNIST(mnist_dir, train=True, download=True,\n",
        "                       transform=transforms.Compose([\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize((0.1307,), (0.3081,))\n",
        "                       ])),\n",
        "        batch_size=batch_size, shuffle=True, **kwargs)\n",
        "  test_loader = torch.utils.data.DataLoader(\n",
        "        datasets.MNIST(mnist_dir, train=False, transform=transforms.Compose([\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize((0.1307,), (0.3081,))\n",
        "                       ])),\n",
        "        batch_size=test_batch_size, shuffle=True, **kwargs)\n",
        "  \n",
        "  return train_loader, test_loader\n",
        "\n",
        "\n",
        "batch_size = 50 \n",
        "test_batch_size = 100\n",
        "mnist_dir = 'datasets/MNIST' # the directory our data will be downloaded too\n",
        "train_loader, test_loader = load_MNIST(mnist_dir, batch_size, test_batch_size, kwargs)\n",
        "print(\"The MNIST data is loaded successfully!\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The MNIST data is loaded successfully!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4GgAWahhhZvJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        ########################################################################\n",
        "        # modify code here:\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)  # first convolutional layer\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5) # second convolutional layer\n",
        "        self.fc1 = nn.Linear(1024, 128) # fully connected layer 1\n",
        "        self.fc2 = nn.Linear(128, 10) # fully connected layer 2\n",
        "        ########################################################################\n",
        "\n",
        "    def forward(self, x):\n",
        "        ########################################################################\n",
        "        # modify code here:\n",
        "        x = self.conv1(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = F.relu(x)\n",
        "        x = x.view(-1, 1024)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        ########################################################################\n",
        "        return F.log_softmax(x, dim=1)\n",
        "    \n",
        "cnn_model_2 = CNN().to(device)    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jKaF2h1ZiaVY",
        "colab_type": "code",
        "outputId": "75c6ac50-33bc-4235-e28d-582b1dcc9d9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "def train(model, device, train_loader, loss_function, optimizer, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        # data has a batch of images\n",
        "        # target is a batch of corresponding training labels\n",
        "        optimizer.zero_grad() # initialize all the gradients with zeros\n",
        "        output = model(data) # compute the network's predictions for the batch of images\n",
        "        loss = loss_function(output, target) # here we calculate the loss value\n",
        "        loss.backward() # compute the gradients for all the weights of the network automatically!\n",
        "        optimizer.step() # here we actually update the network's weights\n",
        "        if batch_idx % 100 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))         \n",
        "print('Training method loaded!')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training method loaded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xB8ioHKvheUg",
        "colab_type": "code",
        "outputId": "d5c941cc-c1cb-4a65-c7e1-333c14954aef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1054
        }
      },
      "cell_type": "code",
      "source": [
        "loss_function = nn.NLLLoss()\n",
        "optimizer = optim.SGD(cnn_model_2.parameters(), lr=0.01, momentum=0.9) # lr - learning rate\n",
        "num_epochs = 5\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "        train(cnn_model_2, device, train_loader, loss_function, optimizer, epoch)\n",
        "print('Training finished') "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.347785\n",
            "Train Epoch: 1 [5000/60000 (8%)]\tLoss: 0.402990\n",
            "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 0.625150\n",
            "Train Epoch: 1 [15000/60000 (25%)]\tLoss: 0.120014\n",
            "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 0.192006\n",
            "Train Epoch: 1 [25000/60000 (42%)]\tLoss: 0.092286\n",
            "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 0.153471\n",
            "Train Epoch: 1 [35000/60000 (58%)]\tLoss: 0.038535\n",
            "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.267275\n",
            "Train Epoch: 1 [45000/60000 (75%)]\tLoss: 0.038398\n",
            "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 0.157141\n",
            "Train Epoch: 1 [55000/60000 (92%)]\tLoss: 0.041399\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.088380\n",
            "Train Epoch: 2 [5000/60000 (8%)]\tLoss: 0.220250\n",
            "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 0.102368\n",
            "Train Epoch: 2 [15000/60000 (25%)]\tLoss: 0.026434\n",
            "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 0.007311\n",
            "Train Epoch: 2 [25000/60000 (42%)]\tLoss: 0.011885\n",
            "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 0.064603\n",
            "Train Epoch: 2 [35000/60000 (58%)]\tLoss: 0.098019\n",
            "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.016510\n",
            "Train Epoch: 2 [45000/60000 (75%)]\tLoss: 0.233867\n",
            "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 0.022680\n",
            "Train Epoch: 2 [55000/60000 (92%)]\tLoss: 0.033493\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.047334\n",
            "Train Epoch: 3 [5000/60000 (8%)]\tLoss: 0.055207\n",
            "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 0.057427\n",
            "Train Epoch: 3 [15000/60000 (25%)]\tLoss: 0.017410\n",
            "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 0.026289\n",
            "Train Epoch: 3 [25000/60000 (42%)]\tLoss: 0.015031\n",
            "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 0.006069\n",
            "Train Epoch: 3 [35000/60000 (58%)]\tLoss: 0.109841\n",
            "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.003473\n",
            "Train Epoch: 3 [45000/60000 (75%)]\tLoss: 0.043211\n",
            "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 0.015744\n",
            "Train Epoch: 3 [55000/60000 (92%)]\tLoss: 0.028257\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.061259\n",
            "Train Epoch: 4 [5000/60000 (8%)]\tLoss: 0.026951\n",
            "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 0.086080\n",
            "Train Epoch: 4 [15000/60000 (25%)]\tLoss: 0.003372\n",
            "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 0.119990\n",
            "Train Epoch: 4 [25000/60000 (42%)]\tLoss: 0.023904\n",
            "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 0.008110\n",
            "Train Epoch: 4 [35000/60000 (58%)]\tLoss: 0.010856\n",
            "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 0.041598\n",
            "Train Epoch: 4 [45000/60000 (75%)]\tLoss: 0.024851\n",
            "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 0.027429\n",
            "Train Epoch: 4 [55000/60000 (92%)]\tLoss: 0.013846\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.014209\n",
            "Train Epoch: 5 [5000/60000 (8%)]\tLoss: 0.004070\n",
            "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 0.034089\n",
            "Train Epoch: 5 [15000/60000 (25%)]\tLoss: 0.015321\n",
            "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 0.024996\n",
            "Train Epoch: 5 [25000/60000 (42%)]\tLoss: 0.004080\n",
            "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 0.021201\n",
            "Train Epoch: 5 [35000/60000 (58%)]\tLoss: 0.069741\n",
            "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 0.022562\n",
            "Train Epoch: 5 [45000/60000 (75%)]\tLoss: 0.033354\n",
            "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 0.025211\n",
            "Train Epoch: 5 [55000/60000 (92%)]\tLoss: 0.008871\n",
            "Training finished\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4nPQMpdkjdvE",
        "colab_type": "code",
        "outputId": "67a6e5f6-36a6-420a-9c09-85bbdccbdcc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += targets.size(0)\n",
        "        correct += (predicted == targets).sum().item()\n",
        "        if batch_idx % 10 == 0:\n",
        "            print('[{}/{}]\\t'\n",
        "                  'Correct: {}\\t'\n",
        "                  'Total: {}\\t'.format(\n",
        "                batch_idx,\n",
        "                len(test_loader),\n",
        "                correct,\n",
        "                total))\n",
        "    if len(test_loader.dataset)==0:\n",
        "        print(\"Error: test data have not been loaded correctly\")\n",
        "        return -1\n",
        "    \n",
        "    accuracy = 100.0 * correct / total\n",
        "\n",
        "    print('Accuracy of the network on the test images: {:.3f}%; correct: {} out of {}'.format(\n",
        "        accuracy, correct, total))\n",
        "    \n",
        "print(\"Test method is loaded successfully\")    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test method is loaded successfully\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iESn2iv3jVcz",
        "colab_type": "code",
        "outputId": "64d5a73d-cbb0-4f0c-d609-1f507684411e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "test(cnn_model_2, device, test_loader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0/100]\tCorrect: 99\tTotal: 100\t\n",
            "[10/100]\tCorrect: 1095\tTotal: 1100\t\n",
            "[20/100]\tCorrect: 2088\tTotal: 2100\t\n",
            "[30/100]\tCorrect: 3081\tTotal: 3100\t\n",
            "[40/100]\tCorrect: 4070\tTotal: 4100\t\n",
            "[50/100]\tCorrect: 5062\tTotal: 5100\t\n",
            "[60/100]\tCorrect: 6055\tTotal: 6100\t\n",
            "[70/100]\tCorrect: 7047\tTotal: 7100\t\n",
            "[80/100]\tCorrect: 8035\tTotal: 8100\t\n",
            "[90/100]\tCorrect: 9025\tTotal: 9100\t\n",
            "Accuracy of the network on the test images: 99.200%; correct: 9920 out of 10000\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}